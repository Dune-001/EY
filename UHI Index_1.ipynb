{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ea3cf34-94dd-45bf-876c-1142168aaf41",
   "metadata": {},
   "source": [
    "# ***Urban Heat Island (UHI) Index using features from Sentinel-2 satelite dataset as predictor variables***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90658f01-0c2e-4f00-8c4c-3b53b8a7acb9",
   "metadata": {},
   "source": [
    "## Loading in Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944d166d-29a3-4e5e-9feb-274e591aac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# installing modules to the environment\n",
    "!pip install geopandas\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data Science\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Multi-dimensional arrays and datasets\n",
    "import xarray as xr\n",
    "\n",
    "# Geospatial raster data handling\n",
    "import rioxarray as rxr\n",
    "\n",
    "# Geospatial data analysis\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Geospatial operations\n",
    "import rasterio\n",
    "from rasterio import windows\n",
    "from rasterio import features\n",
    "from rasterio import warp\n",
    "from rasterio.warp import transform_bounds\n",
    "from rasterio.windows import from_bounds\n",
    "\n",
    "#Image Processing\n",
    "from PIL import Image\n",
    "\n",
    "# Coordinate transformations\n",
    "from pyproj import Proj, Transformer, CRS\n",
    "\n",
    "# Feature Engineering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Planetary Computer Tools\n",
    "import pystac_client\n",
    "import planetary_computer as pc\n",
    "from pystac.extensions.eo import EOExtension as eo\n",
    "\n",
    "# Others\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114f3627-8a59-418f-81fa-d728f885e2a2",
   "metadata": {},
   "source": [
    "## Response Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d062aabf-e8ac-4baa-b2fd-18679150db07",
   "metadata": {},
   "source": [
    "### Loading training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2236a1-9f81-4a52-a3ce-87f6586a3244",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_df = pd.read_csv(\"Training_data_uhi_index_2025-02-18.csv\")\n",
    "ground_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361d74e6-bce2-47d4-bac8-8c878ad7c0a5",
   "metadata": {},
   "source": [
    "## Predictor variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12e4e8e-0c3b-4ee0-a193-66ab04b5f490",
   "metadata": {},
   "source": [
    "### Downloading GeoTIFF Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ad3b37-14c2-48f8-b7c5-4f449e484537",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' read and plot all the six bands from the GeoTIFF file (B04, B08, B06, B01, B11, B03) '''\n",
    "# open the GeoTIFF file\n",
    "tiff_path = \"S2_sample.tiff\"\n",
    "\n",
    "'''# inspecting dimensions and coordinates using xarray(multi-dimensional)\n",
    "data = rxr.open_rasterio(tiff_path)\n",
    "\n",
    "# dimensions and coordinates\n",
    "print(\"Dimensions:\", data.dims)\n",
    "print(\"\\nCoordinates\")\n",
    "print(data.coords)\n",
    "\n",
    "# metadata\n",
    "print(\"\\nAttributes:\")\n",
    "print(data.attrs)\n",
    "\n",
    "# inspecting dimensions and coordinates using rasterio\n",
    "with rasterio.open(tiff_path) as src:\n",
    "    # metadata info\n",
    "    print(\"Metadata:\")\n",
    "    print(src.meta)\n",
    "\n",
    "    # dimension names\n",
    "    print(\"\\nDimensions (width, height):\", src.width, src.height)\n",
    "    print(\"CRS:\", src.crs)\n",
    "\n",
    "    # List all bands\n",
    "    print(\"\\nNumber of Bands:\", src.count)\n",
    "    for i in range(1, src.count + 1):\n",
    "        print(f\"Band {i}:\", src.descriptions[i - 1])'''\n",
    "\n",
    "# Read bands from GeoTIFF\n",
    "with rasterio.open(tiff_path) as src1:\n",
    "    band1 = src1.read(1) # band B01\n",
    "    band2 = src1.read(2) # band B03\n",
    "    band3 = src1.read(3) # band B04\n",
    "    band4 = src1.read(4) # band B05\n",
    "    band5 = src1.read(5) # band B06\n",
    "    band6 = src1.read(6) # band B07\n",
    "    band7 = src1.read(7) # band B08\n",
    "    band8 = src1.read(8) # band B11\n",
    "\n",
    "# plot bands in 2x3 grid\n",
    "fig, axes = plt.subplots(2, 4, figsize=(10, 10))\n",
    "\n",
    "# Flatten the axes for easier indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot the first band (B01)\n",
    "im1 = axes[0].imshow(band1, cmap='viridis')\n",
    "axes[0].set_title('Band [B01]')\n",
    "fig.colorbar(im1, ax=axes[0])\n",
    "\n",
    "# Plot the second band (B03)\n",
    "im2 = axes[1].imshow(band2, cmap='viridis')\n",
    "axes[1].set_title('Band [B03]')\n",
    "fig.colorbar(im2, ax=axes[1])\n",
    "\n",
    "# Plot the third band (B04)\n",
    "im3 = axes[2].imshow(band3, cmap='viridis')\n",
    "axes[2].set_title('Band [B04]')\n",
    "fig.colorbar(im3, ax=axes[2])\n",
    "\n",
    "#Plot the fourth band (B05)\n",
    "im4 = axes[3].imshow(band4, cmap='viridis')\n",
    "axes[3].set_title('Band [B05]')\n",
    "fig.colorbar(im4, ax=axes[3])\n",
    "\n",
    "#Plot the fifth band (B06)\n",
    "im5 = axes[4].imshow(band5, cmap='viridis')\n",
    "axes[4].set_title('Band [B06]')\n",
    "fig.colorbar(im5, ax=axes[4])\n",
    "\n",
    "# Plot the sixth band (B07)\n",
    "im6 = axes[5].imshow(band6, cmap='viridis')\n",
    "axes[5].set_title('Band [B07]')\n",
    "fig.colorbar(im6, ax=axes[5])\n",
    "\n",
    "# Plot the seventh band (B08)\n",
    "im7 = axes[6].imshow(band7, cmap='viridis')\n",
    "axes[6].set_title('Band [B08]')\n",
    "fig.colorbar(im7, ax=axes[6])\n",
    "\n",
    "# Plot the eighth band (B11)\n",
    "im8 = axes[7].imshow(band8, cmap='viridis')\n",
    "axes[7].set_title('Band [B11]')\n",
    "fig.colorbar(im8, ax=axes[7])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa09c992-5a38-45ef-8dba-b0285cdb7eca",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe79515-43d5-42ac-90a0-27dfdd5211b7",
   "metadata": {},
   "source": [
    "### Extracting Band Values from the GeoTIFF Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbb8b82-0b64-4cab-a97f-66dbd2960180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preload data into memory\n",
    "csv_path = \"Training_data_uhi_index_2025-02-18.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7873de-83bc-4606-b4bc-52554c543f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts satellite band values from a GeoTIFF based on coordinates from a csv file and returns them in a DataFrame.\n",
    "# This is a single point data extraction!\n",
    "\n",
    "#df = pd.DataFrame()\n",
    "def map_satellite_data(tiff_path, csv_path):\n",
    "\n",
    "    # load GeoTIFF data\n",
    "    data = rxr.open_rasterio(tiff_path)\n",
    "    tiff_crs = data.rio.crs\n",
    "\n",
    "    # Read the Excel file using pandas\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # checking for missing or NaN vaalues\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "    # checking GeoTIFF Bounds\n",
    "    print(data.rio.bounds())\n",
    "    latitudes = df['Latitude'].values\n",
    "    longitudes = df['Longitude'].values\n",
    "\n",
    "    # convert lat/long to GeoTIFF's CRS\n",
    "    # create Proj object for EPSG:4236 (WGS84 - lat/long) and GeoTIFF's CRS\n",
    "    proj_wgs84 = Proj('EPSG:4326') # EPSG:4236 is the common lat/long CRS\n",
    "    proj_tiff = Proj(tiff_crs)\n",
    "\n",
    "    # Create a transformer object\n",
    "    transformer = Transformer.from_crs('EPSG:4326', tiff_crs, always_xy=True)\n",
    "\n",
    "    B01_values = []\n",
    "    B03_values = []\n",
    "    B04_values = []\n",
    "    B05_values = []\n",
    "    B06_values = []\n",
    "    B07_values = []\n",
    "    B08_values = []\n",
    "    B11_values = []\n",
    "\n",
    "    # loop over the latitudes and longitudes and extract corresponding values\n",
    "    # testing a small sample\n",
    "    #subset_latitudes = latitudes[:10]\n",
    "    #subset_longitudes = longitudes[:10]\n",
    "\n",
    "    # check input data\n",
    "    print(df.dtypes)\n",
    "    print(df[['Latitude', 'Longitude']].head())\n",
    "\n",
    "    # verifying iteration logic\n",
    "    print(f\"Number of coordinates to process: {len(latitudes)}\")\n",
    "    print(f\"Example lat/lon pairs: {list(zip(latitudes, longitudes))[:5]}\")\n",
    "\n",
    "    for lat, lon in tqdm(zip(latitudes, longitudes), total=len(latitudes), desc=\"Mapping values\"):\n",
    "        # assuming correct dimensions are 'y' and 'x'\n",
    "        try:\n",
    "            x, y = transformer.transform(lon, lat)\n",
    "\n",
    "            #testing transformed coordinates with 'data.sel()'\n",
    "            #sample_lat, sample_lon = latitudes[0], longitudes[0]\n",
    "            #x,y = transformer.transform(sample_lon, sample_lat)\n",
    "            #print(f\"Sample transformed coordinates: x={x}, y={y}\")\n",
    "            #print(data.sel(x=x, y=y, band=1, method=\"nearest\").values)\n",
    "\n",
    "            B01_values.append(data.sel(x=x, y=y, band=1, method=\"nearest\").values)\n",
    "            B03_values.append(data.sel(x=x, y=y, band=2, method=\"nearest\").values)\n",
    "            B04_values.append(data.sel(x=x, y=y, band=3, method=\"nearest\").values)\n",
    "            B05_values.append(data.sel(x=x, y=y, band=4, method=\"nearest\").values)\n",
    "            B06_values.append(data.sel(x=x, y=y, band=5, method=\"nearest\").values)\n",
    "            B07_values.append(data.sel(x=x, y=y, band=6, method=\"nearest\").values)\n",
    "            B08_values.append(data.sel(x=x, y=y, band=7, method=\"nearest\").values)\n",
    "            B11_values.append(data.sel(x=x, y=y, band=8, method=\"nearest\").values)\n",
    "            #print(f\"Transformed coordinates: x={x}, y={y}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error transforming coordinates lat={lat}, lon={lon}: {e}\")\n",
    "            continue\n",
    "\n",
    "        except KeyError:\n",
    "            # Handle coordinates outside the bounds of the GeoTIFF\n",
    "            print(f\"Coordinates out of bounds: lat={lat}, lon={lon}\")\n",
    "            B01_values.append(None)\n",
    "            B03_values.append(None)\n",
    "            B04_values.append(None)\n",
    "            B06_values.append(None)\n",
    "            B08_values.append(None)\n",
    "            B11_values.append(None)\n",
    "\n",
    "    # create dataframe with the band values to store them\n",
    "    final_df = pd.DataFrame({\n",
    "        'B01' : B01_values,\n",
    "        'B03' : B03_values,\n",
    "        'B04' : B04_values,\n",
    "        'B05' : B05_values,\n",
    "        'B06' : B06_values,\n",
    "        'B07' : B07_values,\n",
    "        'B08' : B08_values,\n",
    "        'B11' : B11_values\n",
    "    })\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f45f78-e826-4272-9a17-cab0aedd6a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping satellite data with training data\n",
    "final_data = map_satellite_data('S2_sample.tiff', 'Training_data_uhi_index_2025-02-18.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c5a341-b882-448f-ab4a-3e86c0a4bf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_data.head())\n",
    "print(final_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b9675c-1dd6-4670-96aa-b4d1e4b96410",
   "metadata": {},
   "source": [
    "#### Median composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d99ffa5-a732-4da0-ac4a-583406290d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the median composite\n",
    "#data = rxr.open_rasterio(\"S2_sample.tiff\")\n",
    "#data = data.rio.write_crs(\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeb753f-9986-4900-9d80-b479fa8f8638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate median composite along the band dimension\n",
    "#median_composite = data.median(dim=\"band\").compute()\n",
    "#median.rio.to_raster(\"median_composite.tiff\")\n",
    "#print(median_composite)\n",
    "#print(median_composite.dims)\n",
    "#print(median_composite.coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb6423f-101f-4a3d-9b55-112d32d8c899",
   "metadata": {},
   "source": [
    "#### Calculate NDVI (Normalized Difference Vegetation Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fb6719-a8c4-4f33-bfe0-25196d76fb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load median\n",
    "#median = rxr.open_rasterio(\"median_composite.tiff\")\n",
    "#red = median.sel(band=4)\n",
    "#nir = median.sel(band=8)\n",
    "#ndvi = (nir - red) / (nir + red)\n",
    "#final_data['NDVI'] = ndvi\n",
    "final_data['NDVI'] = (final_data['B08'] - final_data['B04']) / (final_data['B08'] + final_data['B04'])\n",
    "# handle division by zero by replacing infinites with NaN\n",
    "final_data['NDVI'] = final_data['NDVI'].replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db87a62-b2d0-43d8-927a-4abb9b456a4a",
   "metadata": {},
   "source": [
    "#### Calculate NDBI (Normalized Difference Buildup Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d819efa-6602-4c27-8019-67d08fc985a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data['NDBI'] = (final_data['B11'] - final_data['B08']) / (final_data['B11'] + final_data['B08'])\n",
    "# handle division by zero by replacing infinites with NaN\n",
    "final_data['NDBI'] = final_data['NDBI'].replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef68dd72-4745-41b7-9a58-eb96b5966dbe",
   "metadata": {},
   "source": [
    "#### Calculate NDWI (Normalized Difference Water Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d066d7a9-7095-43ec-8df0-1bb586d44cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data['NDWI'] = (final_data['B03'] - final_data['B08']) / (final_data['B03'] + final_data['B08'])\n",
    "# handle division by zero by replacing infinites with NaN\n",
    "final_data['NDWI'] = final_data['NDWI'].replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62c43a7-5893-41d6-8593-ef91c80b3643",
   "metadata": {},
   "source": [
    "### Joining the predictor variables and response variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad22e28-f40a-4251-83bb-c1a63e6be69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to combine two datasets vertically (along columns) using pandas concat function.\n",
    "def combine_two_datasets(dataset1, dataset2):\n",
    "    '''\n",
    "    Returns a vertically concantenated dataset.\n",
    "    Attributes:\n",
    "    dataset1 - Dataset 1 to be combined\n",
    "    dataset2 - Dataset 2 to be combined\n",
    "    '''\n",
    "\n",
    "    data = pd.concat([dataset1,dataset2], axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc4d9bf-580f-4d5d-ac08-04c6f13aea00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining ground data and final data into a single dataset\n",
    "uhi_data = combine_two_datasets(ground_df,final_data)\n",
    "uhi_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de5092c-6c96-4961-ab08-1b2d812593fa",
   "metadata": {},
   "source": [
    "#### Removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d11285-94e3-4d0a-b5fe-a84ec8367cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows from the dataframe based on specific columns, keep the first occurrence\n",
    "columns_to_check = ['B01','B03','B04','B05', 'B06','B07', 'B08','B11','NDVI','NDBI','NDWI']\n",
    "for col in columns_to_check:\n",
    "    # Check if the value is a numpy array and has more than one dimension\n",
    "    uhi_data[col] = uhi_data[col].apply(lambda x: tuple(x) if isinstance(x, np.ndarray) and x.ndim > 0 else x)\n",
    "\n",
    "# now remove duplicates\n",
    "uhi_data = uhi_data.drop_duplicates(subset=columns_to_check, keep='first')\n",
    "uhi_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feaec73-601a-4f14-9801-cff0f7ff4e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting the index of the dataset\n",
    "uhi_data=uhi_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ffe563-4dfc-4127-9877-78ce90a4bbd9",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf5a070-2cf5-4f77-9701-82d475f64d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retaining only columns for use in the training dataset\n",
    "uhi_data = uhi_data[['B01', 'B05', 'B06', 'B07', 'NDVI', 'UHI Index']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f661ff4-7d5a-4290-b6fc-4f4475357ea6",
   "metadata": {},
   "source": [
    "### Split data for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1943c37-87f3-410c-99c9-292a6410a2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target (Y)\n",
    "X = uhi_data.drop(columns=['UHI Index']).values\n",
    "Y = uhi_data ['UHI Index'].values\n",
    "\n",
    "# 70/30 split for train and test data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ca852d-79c8-4777-af27-b9eee07a6c76",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b17e01-ad41-4f7c-8bb8-20cf132cddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the training and test data using standard scaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b953ec04-f42a-45a6-87d4-4132461b47ec",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedfbbac-5946-4d1b-9357-9d1ff86ec435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the random forest model on training data\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=123)\n",
    "# fit the training data to the model\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cbf15d-70df-49a5-82dd-661e734145a3",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213a1f30-83a9-4feb-8f05-df16670a0da6",
   "metadata": {},
   "source": [
    "### In-Sample Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9e84e5-0d3e-4b84-a3b2-47bfaa32ba42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on the training data\n",
    "insample_predictions = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21826ef1-a77a-471b-9486-93cae80963cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate R-squared score for insample_predictions\n",
    "y_train = Y_train.tolist()\n",
    "r2_score(y_train, insample_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006eee2d-9612-4136-a995-05d2e6450267",
   "metadata": {},
   "source": [
    "### Out-Sample Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d3f69a-500f-424f-ab5e-aa43dde5a7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "outsample_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9c03a3-3648-434d-90d1-aa66a7360c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate R-squared score for outsample_predictions\n",
    "y_test = Y_test.tolist()\n",
    "r2_score(y_test, outsample_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d78e006-2dd5-4c6c-9b15-246e3d0a8de6",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8022f5-cbc9-486c-9eff-8d17ebf93734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the coordinates for submission\n",
    "test_file = pd.read_csv('Submission_template_UHI2025-v2.csv')\n",
    "test_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e065200-ca0a-408b-9ba8-c289b629ea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping satelite data for submission\n",
    "val_data = map_satellite_data('S2_sample.tiff', 'Submission_template_UHI2025-v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2a9023-4233-4284-93d1-cb8a23afe93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate NDVI (Normalized Difference Vegetation Index)\n",
    "val_data['NDVI'] = (val_data['B08'] - val_data['B04']) / (val_data['B08'] + val_data['B04'])\n",
    "# handle devision by zero by replacing infinites with NaN\n",
    "val_data['NDVI'] = val_data['NDVI'].replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cdc553-6052-4bdf-a700-a074eca45b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c2ed50-c7f4-4ee7-a013-98944fbecb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting specific columns from validation dataset\n",
    "submission_val_data=val_data.loc[:,['B01','B05','B06','B07','NDVI']]\n",
    "submission_val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99f10c5-f8c8-475b-8020-ec06fb0e22d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "submission_val_data = submission_val_data.values\n",
    "transformed_submission_data = sc.transform(submission_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77dc17e-5e4f-4d15-91db-04f7e06db9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "final_predictions = model.predict(transformed_submission_data)\n",
    "final_prediction_series = pd.Series(final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f156b657-eff4-42fa-b2e9-f10728df92cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the results into dataframe\n",
    "submission_df = pd.DataFrame({'Longitude':test_file['Longitude'].values, 'Latitude':test_file['Latitude'].values, 'UHI Index':final_prediction_series.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece0fd3f-c691-48db-ad99-c039e4a45f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the sample submission dataframe\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a7be30-9e30-43c1-b4cc-071d2d436d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dumping the predictions into a csv file\n",
    "submission_df.to_csv(\"submission.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
