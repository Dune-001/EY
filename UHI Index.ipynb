{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ea3cf34-94dd-45bf-876c-1142168aaf41",
   "metadata": {},
   "source": [
    "# ***Urban Heat Island (UHI) Index using features from Sentinel-2 satelite dataset as predictor variables***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90658f01-0c2e-4f00-8c4c-3b53b8a7acb9",
   "metadata": {},
   "source": [
    "## Loading in Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944d166d-29a3-4e5e-9feb-274e591aac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# installing modules to the environment\n",
    "!pip install geopandas\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data Science\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Multi-dimensional arrays and datasets\n",
    "import xarray as xr\n",
    "\n",
    "# Geospatial raster data handling\n",
    "import rioxarray as rxr\n",
    "\n",
    "# Geospatial data analysis\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Geospatial operations\n",
    "import rasterio\n",
    "from rasterio import windows\n",
    "from rasterio import features\n",
    "from rasterio import warp\n",
    "from rasterio.warp import transform_bounds\n",
    "from rasterio.windows import from_bounds\n",
    "\n",
    "#Image Processing\n",
    "from PIL import Image\n",
    "\n",
    "# Coordinate transformations\n",
    "from pyproj import Proj, Transformer, CRS\n",
    "\n",
    "# Feature Engineering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Planetary Computer Tools\n",
    "import pystac_client\n",
    "import planetary_computer as pc\n",
    "from pystac.extensions.eo import EOExtension as eo\n",
    "\n",
    "# Others\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114f3627-8a59-418f-81fa-d728f885e2a2",
   "metadata": {},
   "source": [
    "## Response Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d062aabf-e8ac-4baa-b2fd-18679150db07",
   "metadata": {},
   "source": [
    "### Loading training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2236a1-9f81-4a52-a3ce-87f6586a3244",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_df = pd.read_csv(\"Training_data_uhi_index_2025-02-18.csv\")\n",
    "ground_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361d74e6-bce2-47d4-bac8-8c878ad7c0a5",
   "metadata": {},
   "source": [
    "## Predictor variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12e4e8e-0c3b-4ee0-a193-66ab04b5f490",
   "metadata": {},
   "source": [
    "### Downloading GeoTIFF Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ad3b37-14c2-48f8-b7c5-4f449e484537",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' read and plot all the six bands from the GeoTIFF file (B04, B08, B06, B01, B11, B03) '''\n",
    "# open the GeoTIFF file\n",
    "tiff_path = \"S2_sample.tiff\"\n",
    "\n",
    "'''# inspecting dimensions and coordinates using xarray(multi-dimensional)\n",
    "data = xr.open_rasterio(tiff_path)\n",
    "\n",
    "# dimensions and coordinates\n",
    "print(\"Dimensions:\", data.dims)\n",
    "print(\"\\nCoordinates\")\n",
    "print(data.coords)\n",
    "\n",
    "# metadata\n",
    "print(\"\\nAttributes:\")\n",
    "print(data.attrs)\n",
    "\n",
    "# inspecting dimensions and coordinates using rasterio\n",
    "with rasterio.open(tiff_path) as src:\n",
    "    # metadata info\n",
    "    print(\"Metadata:\")\n",
    "    print(src.meta)\n",
    "\n",
    "    # dimension names\n",
    "    print(\"\\nDimensions (width, height):\", src.width, src.height)\n",
    "    print(\"CRS:\", src.crs)\n",
    "\n",
    "    # List all bands\n",
    "    print(\"\\nNumber of Bands:\", src.count)\n",
    "    for i in range(1, src.count + 1):\n",
    "        print(f\"Band {i}:\", src.descriptions[i - 1])'''\n",
    "\n",
    "# Read bands from GeoTIFF\n",
    "with rasterio.open(tiff_path) as src1:\n",
    "    band1 = src1.read(1) # band B01\n",
    "    band2 = src1.read(3) # band B03\n",
    "    band3 = src1.read(4) # band B04\n",
    "    band4 = src1.read(6) # band B06\n",
    "    band5 = src1.read(8) # band B08\n",
    "    band6 = src1.read(10) # band B11\n",
    "\n",
    "# plot bands in 2x3 grid\n",
    "fig, axes = plt.subplots(2, 3, figsize=(10, 10))\n",
    "\n",
    "# Flatten the axes for easier indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot the first band (B01)\n",
    "im1 = axes[0].imshow(band1, cmap='viridis')\n",
    "axes[0].set_title('Band [B01]')\n",
    "fig.colorbar(im1, ax=axes[0])\n",
    "\n",
    "# Plot the second band (B03)\n",
    "im2 = axes[1].imshow(band2, cmap='viridis')\n",
    "axes[1].set_title('Band [B03]')\n",
    "fig.colorbar(im2, ax=axes[1])\n",
    "\n",
    "# Plot the third band (B04)\n",
    "im3 = axes[2].imshow(band3, cmap='viridis')\n",
    "axes[2].set_title('Band [B04]')\n",
    "fig.colorbar(im3, ax=axes[2])\n",
    "\n",
    "#Plot the fourth band (B06)\n",
    "im4 = axes[3].imshow(band4, cmap='viridis')\n",
    "axes[3].set_title('Band [B06]')\n",
    "fig.colorbar(im4, ax=axes[3])\n",
    "\n",
    "#Plot the fifth band (B08)\n",
    "im5 = axes[4].imshow(band5, cmap='viridis')\n",
    "axes[4].set_title('Band [B08]')\n",
    "fig.colorbar(im5, ax=axes[4])\n",
    "\n",
    "# Plot the sixth band (B11)\n",
    "im6 = axes[5].imshow(band6, cmap='viridis')\n",
    "axes[5].set_title('Band [B11]')\n",
    "fig.colorbar(im6, ax=axes[5])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa09c992-5a38-45ef-8dba-b0285cdb7eca",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe79515-43d5-42ac-90a0-27dfdd5211b7",
   "metadata": {},
   "source": [
    "### Extracting Band Values from the GeoTIFF Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbb8b82-0b64-4cab-a97f-66dbd2960180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preload data into memory\n",
    "csv_path = \"Training_data_uhi_index_2025-02-18.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7873de-83bc-4606-b4bc-52554c543f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts satellite band values from a GeoTIFF based on coordinates from a csv file and returns them in a DataFrame.\n",
    "# This is a single point data extraction!\n",
    "\n",
    "#df = pd.DataFrame()\n",
    "def map_satellite_data(tiff_path, csv_path):\n",
    "    \n",
    "    # load GeoTIFF data\n",
    "    data = rxr.open_rasterio(tiff_path)\n",
    "    tiff_crs = data.rio.crs\n",
    "\n",
    "    # Read the Excel file using pandas\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # checking for missing or NaN vaalues\n",
    "    print(df.isnull().sum())\n",
    "    \n",
    "    # checking GeoTIFF Bounds\n",
    "    print(data.rio.bounds())\n",
    "    latitudes = df['Latitude'].values\n",
    "    longitudes = df['Longitude'].values\n",
    "\n",
    "    # convert lat/long to GeoTIFF's CRS\n",
    "    # create Proj object for EPSG:4236 (WGS84 - lat/long) and GeoTIFF's CRS\n",
    "    proj_wgs84 = Proj('EPSG:4326') # EPSG:4236 is the common lat/long CRS\n",
    "    proj_tiff = Proj(tiff_crs)\n",
    "\n",
    "    # Create a transformer object\n",
    "    transformer = Transformer.from_crs('EPSG:4326', tiff_crs, always_xy=True)\n",
    "    \n",
    "    B01_values = []\n",
    "    B03_values = []\n",
    "    B04_values = []\n",
    "    B06_values = []\n",
    "    B08_values = []\n",
    "    B11_values = []\n",
    "\n",
    "    # loop over the latitudes and longitudes and extract corresponding values\n",
    "    # testing a small sample\n",
    "    #subset_latitudes = latitudes[:10]\n",
    "    #subset_longitudes = longitudes[:10]\n",
    "\n",
    "    # check input data\n",
    "    print(df.dtypes)\n",
    "    print(df[['Latitude', 'Longitude']].head())\n",
    "    \n",
    "    # verifying iteration logic\n",
    "    print(f\"Number of coordinates to process: {len(latitudes)}\")\n",
    "    print(f\"Example lat/lon pairs: {list(zip(latitudes, longitudes))[:5]}\")\n",
    "\n",
    "    for lat, lon in tqdm(zip(latitudes, longitudes), total=len(latitudes), desc=\"Mapping values\"):\n",
    "        # assuming correct dimensions are 'y' and 'x'\n",
    "        try:\n",
    "            x, y = transformer.transform(lon, lat)\n",
    "\n",
    "            #testing transformed coordinates with 'data.sel()'\n",
    "            #sample_lat, sample_lon = latitudes[0], longitudes[0]\n",
    "            #x,y = transformer.transform(sample_lon, sample_lat)\n",
    "            #print(f\"Sample transformed coordinates: x={x}, y={y}\")\n",
    "            #print(data.sel(x=x, y=y, band=1, method=\"nearest\").values)\n",
    "            \n",
    "            B01_values.append(data.sel(x=x, y=y, band=1, method=\"nearest\").values)\n",
    "            B03_values.append(data.sel(x=x, y=y, band=2, method=\"nearest\").values)\n",
    "            B04_values.append(data.sel(x=x, y=y, band=3, method=\"nearest\").values)\n",
    "            B06_values.append(data.sel(x=x, y=y, band=4, method=\"nearest\").values)\n",
    "            B08_values.append(data.sel(x=x, y=y, band=5, method=\"nearest\").values)\n",
    "            B11_values.append(data.sel(x=x, y=y, band=6, method=\"nearest\").values)\n",
    "            #print(f\"Transformed coordinates: x={x}, y={y}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error transforming coordinates lat={lat}, lon={lon}: {e}\")\n",
    "            continue\n",
    "            \n",
    "        except KeyError:\n",
    "            # Handle coordinates outside the bounds of the GeoTIFF\n",
    "            print(f\"Coordinates out of bounds: lat={lat}, lon={lon}\")\n",
    "            B01_values.append(None)\n",
    "            B03_values.append(None)\n",
    "            B04_values.append(None)\n",
    "            B06_values.append(None)\n",
    "            B08_values.append(None)\n",
    "            B11_values.append(None)\n",
    "            \n",
    "    # create dataframe with the band values to store them\n",
    "    final_df = pd.DataFrame({\n",
    "        'B01' : B01_values,\n",
    "        'B03' : B03_values,\n",
    "        'B04' : B04_values,\n",
    "        'B06' : B06_values,\n",
    "        'B08' : B08_values,\n",
    "        'B11' : B11_values\n",
    "    })\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f45f78-e826-4272-9a17-cab0aedd6a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping satellite data with training data\n",
    "final_data = map_satellite_data('S2_sample.tiff', 'Training_data_uhi_index_2025-02-18.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c5a341-b882-448f-ab4a-3e86c0a4bf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_data.head())\n",
    "print(final_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb6423f-101f-4a3d-9b55-112d32d8c899",
   "metadata": {},
   "source": [
    "#### Calculate NDVI (Normalized Difference Vegetation Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fb6719-a8c4-4f33-bfe0-25196d76fb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data['NDVI'] = (final_data['B08'] - final_data['B04']) / (final_data['B08'] + final_data['B04'])\n",
    "# handle division by zero by replacing infinites with NaN\n",
    "final_data['NDVI'] = final_data['NDVI'].replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db87a62-b2d0-43d8-927a-4abb9b456a4a",
   "metadata": {},
   "source": [
    "#### Calculate NDBI (Normalized Difference Buildup Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d819efa-6602-4c27-8019-67d08fc985a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data['NDBI'] = (final_data['B11'] - final_data['B08']) / (final_data['B11'] + final_data['B08'])\n",
    "# handle division by zero by replacing infinites with NaN\n",
    "final_data['NDBI'] = final_data['NDBI'].replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef68dd72-4745-41b7-9a58-eb96b5966dbe",
   "metadata": {},
   "source": [
    "#### Calculate NDWI (Normalized Difference Water Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d066d7a9-7095-43ec-8df0-1bb586d44cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data['NDWI'] = (final_data['B03'] - final_data['B08']) / (final_data['B03'] + final_data['B08'])\n",
    "# handle division by zero by replacing infinites with NaN\n",
    "final_data['NDWI'] = final_data['NDWI'].replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62c43a7-5893-41d6-8593-ef91c80b3643",
   "metadata": {},
   "source": [
    "### Joining the predictor variables and response variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad22e28-f40a-4251-83bb-c1a63e6be69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to combine two datasets vertically (along columns) using pandas concat function.\n",
    "def combine_two_datasets(dataset1, dataset2):\n",
    "    '''\n",
    "    Returns a vertically concantenated dataset.\n",
    "    Attributes:\n",
    "    dataset1 - Dataset 1 to be combined\n",
    "    dataset2 - Dataset 2 to be combined\n",
    "    '''\n",
    "\n",
    "    data = pd.concat([dataset1,dataset2], axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc4d9bf-580f-4d5d-ac08-04c6f13aea00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining ground data and final data into a single dataset\n",
    "uhi_data = combine_two_datasets(ground_df,final_data)\n",
    "uhi_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de5092c-6c96-4961-ab08-1b2d812593fa",
   "metadata": {},
   "source": [
    "#### Removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d11285-94e3-4d0a-b5fe-a84ec8367cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows from the dataframe based on specific columns, keep the first occurrence\n",
    "columns_to_check = ['B01','B03','B04','B06','B08','B11','NDVI','NDBI','NDWI']\n",
    "for col in columns_to_check:\n",
    "    # Check if the value is a numpy array and has more than one dimension\n",
    "    uhi_data[col] = uhi_data[col].apply(lambda x: tuple(x) if isinstance(x, np.ndarray) and x.ndim > 0 else x)\n",
    "\n",
    "# now remove duplicates\n",
    "uhi_data = uhi_data.drop_duplicates(subset=columns_to_check, keep='first')\n",
    "uhi_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feaec73-601a-4f14-9801-cff0f7ff4e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting the index of the dataset\n",
    "uhi_data=uhi_data.reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
